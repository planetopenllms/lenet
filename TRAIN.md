# Trainig Output / Dump

to train a LeNetv5 model - try

    $ python ./train.py

resulting in:

```
1/10 - batch 0/938 - loss 2.308006763458252 - running_loss 2.308006763458252, total 64
1/10 - batch 100/938 - loss 0.32441049814224243 - running_loss 0.8908599604769508, total 6464
1/10 - batch 200/938 - loss 0.4516482949256897 - running_loss 0.6226866989586484, total 12864
1/10 - batch 300/938 - loss 0.2625478208065033 - running_loss 0.5104667841150515, total 19264
1/10 - batch 400/938 - loss 0.1436673253774643 - running_loss 0.44020818021529334, total 25664
1/10 - batch 500/938 - loss 0.12447628378868103 - running_loss 0.3890243548000168, total 32064
1/10 - batch 600/938 - loss 0.11431190371513367 - running_loss 0.35106369937938975, total 38464
1/10 - batch 700/938 - loss 0.11063681542873383 - running_loss 0.32078970098514614, total 44864
1/10 - batch 800/938 - loss 0.10062398761510849 - running_loss 0.29703785490695755, total 51264
1/10 - batch 900/938 - loss 0.17651152610778809 - running_loss 0.27672823658884893, total 57664

==> Epoch [1/10], Loss: 0.2701, Accuracy: 92.05%
Test Accuracy: 96.44%

2/10 - batch 0/938 - loss 0.08664247393608093 - running_loss 0.08664247393608093, total 64
2/10 - batch 100/938 - loss 0.04539339244365692 - running_loss 0.0976015107595537, total 6464
2/10 - batch 200/938 - loss 0.15731275081634521 - running_loss 0.09138798323084614, total 12864
2/10 - batch 300/938 - loss 0.04127367213368416 - running_loss 0.09066028288717187, total 19264
2/10 - batch 400/938 - loss 0.04065002501010895 - running_loss 0.08952568121895454, total 25664
2/10 - batch 500/938 - loss 0.029118504375219345 - running_loss 0.08907339715597754, total 32064
2/10 - batch 600/938 - loss 0.04270026087760925 - running_loss 0.08779265551662038, total 38464
2/10 - batch 700/938 - loss 0.06589948385953903 - running_loss 0.08713026525726417, total 44864
2/10 - batch 800/938 - loss 0.03883814811706543 - running_loss 0.0844754423474086, total 51264
2/10 - batch 900/938 - loss 0.03781180828809738 - running_loss 0.08413421880292575, total 57664

==> Epoch [2/10], Loss: 0.0835, Accuracy: 97.46%
Test Accuracy: 97.90%

3/10 - batch 0/938 - loss 0.02772924304008484 - running_loss 0.02772924304008484, total 64
3/10 - batch 100/938 - loss 0.049744442105293274 - running_loss 0.05899657981728416, total 6464
3/10 - batch 200/938 - loss 0.09626119583845139 - running_loss 0.057010590968727695, total 12864
3/10 - batch 300/938 - loss 0.007539339829236269 - running_loss 0.0541924466123724, total 19264
3/10 - batch 400/938 - loss 0.15896892547607422 - running_loss 0.05663230785335927, total 25664
3/10 - batch 500/938 - loss 0.05710975080728531 - running_loss 0.056284213922415935, total 32064
3/10 - batch 600/938 - loss 0.024318687617778778 - running_loss 0.05623077179619829, total 38464
3/10 - batch 700/938 - loss 0.06443814188241959 - running_loss 0.056466468158158103, total 44864
3/10 - batch 800/938 - loss 0.03888627886772156 - running_loss 0.058145103763937764, total 51264
3/10 - batch 900/938 - loss 0.05875040218234062 - running_loss 0.05756111202485545, total 57664

==> Epoch [3/10], Loss: 0.0575, Accuracy: 98.22%
Test Accuracy: 98.02%

==> Epoch [4/10], Loss: 0.0437, Accuracy: 98.67%
Test Accuracy: 98.18%

==> Epoch [5/10], Loss: 0.0356, Accuracy: 98.88%
Test Accuracy: 98.45%

==> Epoch [6/10], Loss: 0.0292, Accuracy: 99.08%
Test Accuracy: 98.12%

==> Epoch [7/10], Loss: 0.0244, Accuracy: 99.23%
Test Accuracy: 98.32%

==> Epoch [8/10], Loss: 0.0219, Accuracy: 99.28%
Test Accuracy: 98.46%

==> Epoch [9/10], Loss: 0.0195, Accuracy: 99.39%
Test Accuracy: 98.27%

==> Epoch [10/10], Loss: 0.0155, Accuracy: 99.50%
Test Accuracy: 98.55%
```

